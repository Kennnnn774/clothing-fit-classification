{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fengj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "from collections import defaultdict # Dictionaries with default values\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent = pd.read_csv('clean.csv')\n",
    "rent.review_summary = rent.review_summary.fillna('')\n",
    "rent.review_text = rent.review_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent = rent.sample(frac=1).reset_index(drop=True)\n",
    "train = rent[:180000]\n",
    "valid = rent[180000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.fit\n",
    "y_valid = valid.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>rating</th>\n",
       "      <th>rented for</th>\n",
       "      <th>review_text</th>\n",
       "      <th>body type</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>category</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "      <th>age</th>\n",
       "      <th>review_date</th>\n",
       "      <th>size_guess_fit</th>\n",
       "      <th>bust_num</th>\n",
       "      <th>bust_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit</td>\n",
       "      <td>208774</td>\n",
       "      <td>153475</td>\n",
       "      <td>15.8725</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>The 10l was snug on my chest 36d but the 12l w...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>Felt like a movie star! Dress came as ordered ...</td>\n",
       "      <td>culott</td>\n",
       "      <td>9.37</td>\n",
       "      <td>12.754825</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>June 29, 2014</td>\n",
       "      <td>37.997325</td>\n",
       "      <td>38</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fit</td>\n",
       "      <td>847724</td>\n",
       "      <td>1436642</td>\n",
       "      <td>1.3605</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>I want to own this dress, I loved it so much! ...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>Great pink color, worked wonderfully for a bab...</td>\n",
       "      <td>culott</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-4.245175</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>April 8, 2017</td>\n",
       "      <td>-1.134675</td>\n",
       "      <td>36</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fit</td>\n",
       "      <td>2635</td>\n",
       "      <td>1996590</td>\n",
       "      <td>-0.9070</td>\n",
       "      <td>8.0</td>\n",
       "      <td>party</td>\n",
       "      <td>I got a lot of compliments about how cute this...</td>\n",
       "      <td>full bust</td>\n",
       "      <td>Comfortable but fun!</td>\n",
       "      <td>culott</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>-8.245175</td>\n",
       "      <td>3.663562</td>\n",
       "      <td>January 28, 2013</td>\n",
       "      <td>-22.642175</td>\n",
       "      <td>36</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>large</td>\n",
       "      <td>999231</td>\n",
       "      <td>1852099</td>\n",
       "      <td>-0.9070</td>\n",
       "      <td>10.0</td>\n",
       "      <td>everyday</td>\n",
       "      <td>Super comfortable dress by Nicole Miller. Runn...</td>\n",
       "      <td>other</td>\n",
       "      <td>STYLIST REVIEW!!</td>\n",
       "      <td>culott</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-4.245175</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>September 9, 2016</td>\n",
       "      <td>-5.942175</td>\n",
       "      <td>34</td>\n",
       "      <td>dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fit</td>\n",
       "      <td>105485</td>\n",
       "      <td>178058</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>date</td>\n",
       "      <td>This dress fit great, except it was a little t...</td>\n",
       "      <td>pear</td>\n",
       "      <td>Comfy, but tight in bust.</td>\n",
       "      <td>culott</td>\n",
       "      <td>-5.87</td>\n",
       "      <td>3.754825</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>September 16, 2013</td>\n",
       "      <td>-2.115175</td>\n",
       "      <td>34</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179995</th>\n",
       "      <td>fit</td>\n",
       "      <td>676596</td>\n",
       "      <td>136110</td>\n",
       "      <td>14.9655</td>\n",
       "      <td>10.0</td>\n",
       "      <td>party</td>\n",
       "      <td>Perfect flare dress, sleeves the perfect tight...</td>\n",
       "      <td>full bust</td>\n",
       "      <td>Beautiful dress. The color was amazing and the...</td>\n",
       "      <td>culott</td>\n",
       "      <td>1.75</td>\n",
       "      <td>26.754825</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>March 15, 2016</td>\n",
       "      <td>43.470325</td>\n",
       "      <td>38</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179996</th>\n",
       "      <td>large</td>\n",
       "      <td>748397</td>\n",
       "      <td>2696735</td>\n",
       "      <td>-5.4420</td>\n",
       "      <td>8.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Have this currently in my Unlimited Order. 4 i...</td>\n",
       "      <td>pear</td>\n",
       "      <td>Great to throw on top of everything</td>\n",
       "      <td>coat</td>\n",
       "      <td>4.29</td>\n",
       "      <td>-4.245175</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>February 2, 2015</td>\n",
       "      <td>-5.397175</td>\n",
       "      <td>34</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179997</th>\n",
       "      <td>large</td>\n",
       "      <td>135436</td>\n",
       "      <td>955151</td>\n",
       "      <td>-5.8955</td>\n",
       "      <td>10.0</td>\n",
       "      <td>everyday</td>\n",
       "      <td>This dress runs slightly big.  I loved the loo...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>Cute summer date night dress</td>\n",
       "      <td>culott</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-4.245175</td>\n",
       "      <td>3.737670</td>\n",
       "      <td>July 23, 2017</td>\n",
       "      <td>-10.930675</td>\n",
       "      <td>34</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179998</th>\n",
       "      <td>fit</td>\n",
       "      <td>946761</td>\n",
       "      <td>1586334</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>party</td>\n",
       "      <td>I did get a lot of compliments on the dress, b...</td>\n",
       "      <td>other</td>\n",
       "      <td>The dress was a great pick for an evening gala...</td>\n",
       "      <td>culott</td>\n",
       "      <td>4.29</td>\n",
       "      <td>7.754825</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>November 5, 2017</td>\n",
       "      <td>12.044825</td>\n",
       "      <td>36</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179999</th>\n",
       "      <td>fit</td>\n",
       "      <td>294636</td>\n",
       "      <td>1800440</td>\n",
       "      <td>12.6980</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>The material was nice and thick and stretchy, ...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>Perfect for Winter Wedding</td>\n",
       "      <td>culott</td>\n",
       "      <td>1.75</td>\n",
       "      <td>7.754825</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>January 21, 2016</td>\n",
       "      <td>22.202825</td>\n",
       "      <td>38</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fit  user_id  item_id   weight  rating rented for  \\\n",
       "0         fit   208774   153475  15.8725    10.0    wedding   \n",
       "1         fit   847724  1436642   1.3605    10.0    wedding   \n",
       "2         fit     2635  1996590  -0.9070     8.0      party   \n",
       "3       large   999231  1852099  -0.9070    10.0   everyday   \n",
       "4         fit   105485   178058   0.0000     8.0       date   \n",
       "...       ...      ...      ...      ...     ...        ...   \n",
       "179995    fit   676596   136110  14.9655    10.0      party   \n",
       "179996  large   748397  2696735  -5.4420     8.0      other   \n",
       "179997  large   135436   955151  -5.8955    10.0   everyday   \n",
       "179998    fit   946761  1586334   0.0000     8.0      party   \n",
       "179999    fit   294636  1800440  12.6980    10.0    wedding   \n",
       "\n",
       "                                              review_text  body type  \\\n",
       "0       The 10l was snug on my chest 36d but the 12l w...  hourglass   \n",
       "1       I want to own this dress, I loved it so much! ...   athletic   \n",
       "2       I got a lot of compliments about how cute this...  full bust   \n",
       "3       Super comfortable dress by Nicole Miller. Runn...      other   \n",
       "4       This dress fit great, except it was a little t...       pear   \n",
       "...                                                   ...        ...   \n",
       "179995  Perfect flare dress, sleeves the perfect tight...  full bust   \n",
       "179996  Have this currently in my Unlimited Order. 4 i...       pear   \n",
       "179997  This dress runs slightly big.  I loved the loo...   athletic   \n",
       "179998  I did get a lot of compliments on the dress, b...      other   \n",
       "179999  The material was nice and thick and stretchy, ...  hourglass   \n",
       "\n",
       "                                           review_summary category  height  \\\n",
       "0       Felt like a movie star! Dress came as ordered ...   culott    9.37   \n",
       "1       Great pink color, worked wonderfully for a bab...   culott    1.75   \n",
       "2                                    Comfortable but fun!   culott  -13.49   \n",
       "3                                        STYLIST REVIEW!!   culott   -0.79   \n",
       "4                               Comfy, but tight in bust.   culott   -5.87   \n",
       "...                                                   ...      ...     ...   \n",
       "179995  Beautiful dress. The color was amazing and the...   culott    1.75   \n",
       "179996                Great to throw on top of everything     coat    4.29   \n",
       "179997                       Cute summer date night dress   culott   -0.79   \n",
       "179998  The dress was a great pick for an evening gala...   culott    4.29   \n",
       "179999                         Perfect for Winter Wedding   culott    1.75   \n",
       "\n",
       "             size       age         review_date  size_guess_fit  bust_num  \\\n",
       "0       12.754825  3.526361       June 29, 2014       37.997325        38   \n",
       "1       -4.245175  3.555348       April 8, 2017       -1.134675        36   \n",
       "2       -8.245175  3.663562    January 28, 2013      -22.642175        36   \n",
       "3       -4.245175  3.295837   September 9, 2016       -5.942175        34   \n",
       "4        3.754825  3.713572  September 16, 2013       -2.115175        34   \n",
       "...           ...       ...                 ...             ...       ...   \n",
       "179995  26.754825  3.295837      March 15, 2016       43.470325        38   \n",
       "179996  -4.245175  3.610918    February 2, 2015       -5.397175        34   \n",
       "179997  -4.245175  3.737670       July 23, 2017      -10.930675        34   \n",
       "179998   7.754825  3.526361    November 5, 2017       12.044825        36   \n",
       "179999   7.754825  3.465736    January 21, 2016       22.202825        38   \n",
       "\n",
       "       bust_char  \n",
       "0              d  \n",
       "1              b  \n",
       "2              c  \n",
       "3             dd  \n",
       "4              d  \n",
       "...          ...  \n",
       "179995         d  \n",
       "179996         c  \n",
       "179997         d  \n",
       "179998         c  \n",
       "179999         d  \n",
       "\n",
       "[180000 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', sublinear_tf = True, max_features = 1000, tokenizer = word_tokenize) \n",
    "Train_X_summary = tfidf.fit_transform(train.review_summary).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(stop_words = 'english', sublinear_tf = True, max_features = 1000, tokenizer = word_tokenize) \n",
    "Train_X_text = tfidf2.fit_transform(train.review_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_train = np.array([train['category'].to_list()]).transpose()\n",
    "weight_train = np.array([train['weight'].to_list()]).transpose()\n",
    "age_train = np.array([train['age'].to_list()]).transpose()\n",
    "height_train = np.array([train['height'].to_list()]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = np.hstack((Train_X_summary, Train_X_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_feature = np.hstack(( category_train,weight_train,age_train,height_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 2000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsss = []\n",
    "for i in range(180000):\n",
    "    lst = list(combined_text[i]) + list(other_feature[i])\n",
    "    lstsss.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feature = lstsss[:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.79 GiB for an array with shape (120000, 2004) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-9871d9833c99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mD:\\Program Files\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.79 GiB for an array with shape (120000, 2004) and data type float64"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(final_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_X_summary = tfidf.transform(valid.review_summary).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_X_text = tfidf2.transform(valid.review_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text_valid = np.hstack((Valid_X_summary, Valid_X_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_valid = np.array([valid['category'].to_list()]).transpose()\n",
    "weight_valid = np.array([valid['weight'].to_list()]).transpose()\n",
    "age_valid = np.array([valid['age'].to_list()]).transpose()\n",
    "height_valid = np.array([valid['height'].to_list()]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_feature_valid = np.hstack((category_valid,weight_valid,age_valid,height_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feature_valid = np.hstack((combined_text_valid, other_feature_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kennnnnnn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:268: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = check_array(X, accept_sparse='csr')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2004 features per sample; expecting 2000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-98aaee70aa93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_feature_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 273\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2004 features per sample; expecting 2000"
     ]
    }
   ],
   "source": [
    "clf.score(final_feature_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit      9235\n",
       "small    1698\n",
       "large    1611\n",
       "Name: fit, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362085459183674"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9235 / (len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter = 10000, C=0.1)\n",
    "clf.fit(combined_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038903061224489"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(combined_text_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
