{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Kennnnnnn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "from collections import defaultdict # Dictionaries with default values\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent = pd.read_csv('clean.csv')\n",
    "rent.review_summary = rent.review_summary.fillna('')\n",
    "rent.review_text = rent.review_text.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent = rent.sample(frac=1).reset_index(drop=True)\n",
    "train = rent[:180000]\n",
    "valid = rent[180000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.fit\n",
    "y_valid = valid.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['date', 'everyday', 'formal affair', 'other', 'party',\n",
       "       'party: cocktail', 'vacation', 'wedding', 'work'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rent['rented for'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'athletic', 'full bust', 'hourglass', 'other', 'pear',\n",
       "       'petite', 'straight & narrow'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rent['body type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'b', 'c', 'd', 'd+', 'dd', 'ddd/e', 'f', 'g', 'h', 'i',\n",
       "       'j'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rent['bust_char'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bot', 'long', 'top_long', 'top_short'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rent['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>rating</th>\n",
       "      <th>rented for</th>\n",
       "      <th>review_text</th>\n",
       "      <th>body type</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>category</th>\n",
       "      <th>height</th>\n",
       "      <th>size</th>\n",
       "      <th>age</th>\n",
       "      <th>review_date</th>\n",
       "      <th>bust_num</th>\n",
       "      <th>bust_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit</td>\n",
       "      <td>351011</td>\n",
       "      <td>1076484</td>\n",
       "      <td>4.9885</td>\n",
       "      <td>8.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>A little tight through the waist...still recov...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>Had a great time in the dress. Felt beautiful....</td>\n",
       "      <td>long</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.245175</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>February 16, 2015</td>\n",
       "      <td>34</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large</td>\n",
       "      <td>313762</td>\n",
       "      <td>921642</td>\n",
       "      <td>-3.1745</td>\n",
       "      <td>8.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>Pretty dress. Runs large in the bust. I wore t...</td>\n",
       "      <td>other</td>\n",
       "      <td>Pretty dress, large bust.</td>\n",
       "      <td>long</td>\n",
       "      <td>4.29</td>\n",
       "      <td>-4.245175</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>June 27, 2017</td>\n",
       "      <td>34</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>large</td>\n",
       "      <td>252800</td>\n",
       "      <td>132738</td>\n",
       "      <td>-0.9070</td>\n",
       "      <td>10.0</td>\n",
       "      <td>formal affair</td>\n",
       "      <td>Hey Guys,\\n\\nI wore this to the 2012, 54th Gra...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>I stood out even at such a huge event like the...</td>\n",
       "      <td>long</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-11.245175</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>February 26, 2012</td>\n",
       "      <td>36</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fit</td>\n",
       "      <td>429675</td>\n",
       "      <td>145906</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>wedding</td>\n",
       "      <td>The dress does run long, even though I was wea...</td>\n",
       "      <td>petite</td>\n",
       "      <td>Felt amazing in this gorgeous gown at a black ...</td>\n",
       "      <td>long</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>-12.245175</td>\n",
       "      <td>3.178054</td>\n",
       "      <td>October 30, 2013</td>\n",
       "      <td>34</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>large</td>\n",
       "      <td>149493</td>\n",
       "      <td>2284114</td>\n",
       "      <td>5.8955</td>\n",
       "      <td>8.0</td>\n",
       "      <td>work</td>\n",
       "      <td>cute, but ran a little bit big. i think i woul...</td>\n",
       "      <td>hourglass</td>\n",
       "      <td>Cute top</td>\n",
       "      <td>top_short</td>\n",
       "      <td>-3.33</td>\n",
       "      <td>7.754825</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>October 10, 2017</td>\n",
       "      <td>36</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192539</th>\n",
       "      <td>large</td>\n",
       "      <td>178433</td>\n",
       "      <td>1436642</td>\n",
       "      <td>-5.4420</td>\n",
       "      <td>6.0</td>\n",
       "      <td>vacation</td>\n",
       "      <td>This dress is a thicker material and pretty co...</td>\n",
       "      <td>petite</td>\n",
       "      <td>.</td>\n",
       "      <td>long</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>-0.245175</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>July 6, 2017</td>\n",
       "      <td>34</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192540</th>\n",
       "      <td>fit</td>\n",
       "      <td>788097</td>\n",
       "      <td>475151</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>other</td>\n",
       "      <td>A fun rental of a floaty feminine dress. There...</td>\n",
       "      <td>athletic</td>\n",
       "      <td>Ethereal, flattering evening dress.</td>\n",
       "      <td>long</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.245175</td>\n",
       "      <td>4.043051</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>32</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192541</th>\n",
       "      <td>fit</td>\n",
       "      <td>366010</td>\n",
       "      <td>295362</td>\n",
       "      <td>-5.4420</td>\n",
       "      <td>10.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Fit was perfect.  Very comfortable to wear.  T...</td>\n",
       "      <td>pear</td>\n",
       "      <td>I wore this to a charity dinner that was busin...</td>\n",
       "      <td>long</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>1.754825</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>October 18, 2017</td>\n",
       "      <td>32</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192542</th>\n",
       "      <td>fit</td>\n",
       "      <td>434105</td>\n",
       "      <td>985499</td>\n",
       "      <td>5.8955</td>\n",
       "      <td>8.0</td>\n",
       "      <td>formal affair</td>\n",
       "      <td>It fit true to size and I am glad I got the \"l...</td>\n",
       "      <td>other</td>\n",
       "      <td>I LOVED this dress and received so many compli...</td>\n",
       "      <td>long</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.754825</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>August 10, 2015</td>\n",
       "      <td>36</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192543</th>\n",
       "      <td>fit</td>\n",
       "      <td>96749</td>\n",
       "      <td>2268666</td>\n",
       "      <td>-9.9770</td>\n",
       "      <td>10.0</td>\n",
       "      <td>vacation</td>\n",
       "      <td>Adorable for cover up...free flowing and comfo...</td>\n",
       "      <td>full bust</td>\n",
       "      <td>Vacation</td>\n",
       "      <td>long</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>-8.245175</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>March 22, 2016</td>\n",
       "      <td>34</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192544 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fit  user_id  item_id  weight  rating     rented for  \\\n",
       "0         fit   351011  1076484  4.9885     8.0        wedding   \n",
       "1       large   313762   921642 -3.1745     8.0        wedding   \n",
       "2       large   252800   132738 -0.9070    10.0  formal affair   \n",
       "3         fit   429675   145906  0.0000    10.0        wedding   \n",
       "4       large   149493  2284114  5.8955     8.0           work   \n",
       "...       ...      ...      ...     ...     ...            ...   \n",
       "192539  large   178433  1436642 -5.4420     6.0       vacation   \n",
       "192540    fit   788097   475151  0.0000     8.0          other   \n",
       "192541    fit   366010   295362 -5.4420    10.0          other   \n",
       "192542    fit   434105   985499  5.8955     8.0  formal affair   \n",
       "192543    fit    96749  2268666 -9.9770    10.0       vacation   \n",
       "\n",
       "                                              review_text  body type  \\\n",
       "0       A little tight through the waist...still recov...  hourglass   \n",
       "1       Pretty dress. Runs large in the bust. I wore t...      other   \n",
       "2       Hey Guys,\\n\\nI wore this to the 2012, 54th Gra...  hourglass   \n",
       "3       The dress does run long, even though I was wea...     petite   \n",
       "4       cute, but ran a little bit big. i think i woul...  hourglass   \n",
       "...                                                   ...        ...   \n",
       "192539  This dress is a thicker material and pretty co...     petite   \n",
       "192540  A fun rental of a floaty feminine dress. There...   athletic   \n",
       "192541  Fit was perfect.  Very comfortable to wear.  T...       pear   \n",
       "192542  It fit true to size and I am glad I got the \"l...      other   \n",
       "192543  Adorable for cover up...free flowing and comfo...  full bust   \n",
       "\n",
       "                                           review_summary   category  height  \\\n",
       "0       Had a great time in the dress. Felt beautiful....       long   -0.79   \n",
       "1                              Pretty dress, large bust.        long    4.29   \n",
       "2       I stood out even at such a huge event like the...       long    1.75   \n",
       "3       Felt amazing in this gorgeous gown at a black ...       long  -13.49   \n",
       "4                                                Cute top  top_short   -3.33   \n",
       "...                                                   ...        ...     ...   \n",
       "192539                                                  .       long   -8.41   \n",
       "192540              Ethereal, flattering evening dress.         long   -0.79   \n",
       "192541  I wore this to a charity dinner that was busin...       long   -8.41   \n",
       "192542  I LOVED this dress and received so many compli...       long    1.75   \n",
       "192543                                           Vacation       long   -8.41   \n",
       "\n",
       "             size       age        review_date  bust_num bust_char  \n",
       "0       -0.245175  3.871201  February 16, 2015        34         b  \n",
       "1       -4.245175  3.583519      June 27, 2017        34         a  \n",
       "2      -11.245175  3.367296  February 26, 2012        36         c  \n",
       "3      -12.245175  3.178054   October 30, 2013        34         c  \n",
       "4        7.754825  3.218876   October 10, 2017        36         d  \n",
       "...           ...       ...                ...       ...       ...  \n",
       "192539  -0.245175  3.688879       July 6, 2017        34         b  \n",
       "192540  -0.245175  4.043051  November 16, 2017        32         a  \n",
       "192541   1.754825  3.951244   October 18, 2017        32         d  \n",
       "192542   0.754825  3.637586    August 10, 2015        36         b  \n",
       "192543  -8.245175  3.367296     March 22, 2016        34         d  \n",
       "\n",
       "[192544 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.87120101],\n",
       "       [3.58351894],\n",
       "       [3.36729583],\n",
       "       ...,\n",
       "       [3.95124372],\n",
       "       [3.63758616],\n",
       "       [3.36729583]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent[['age']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rented_for_one= pd.get_dummies(rent['rented for'], prefix='rented for')\n",
    "category_one = pd.get_dummies(rent['category'], prefix='category')\n",
    "bust_char_one = pd.get_dummies(rent['bust_char'], prefix='bust_char')\n",
    "body_type_one = pd.get_dummies(rent['body type'], prefix='body type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rented_for\n",
    "# rented_for_train = rented_for_one[:180000].to_numpy()\n",
    "# rented_for_valid = rented_for_one[180000:].to_numpy()\n",
    "\n",
    "#category\n",
    "# category_one_train = category_one[:180000].to_numpy()\n",
    "# category_one_valid = category_one[180000:].to_numpy()\n",
    "\n",
    "#bust_num\n",
    "# bust_num_train = train[['bust_num']].to_numpy()\n",
    "# bust_num_valid = valid[['bust_num']].to_numpy()\n",
    "\n",
    "#bust_char\n",
    "# bust_char_for_train = bust_char_one[:180000].to_numpy()\n",
    "# bust_char_for_valid = bust_char_one[180000:].to_numpy()\n",
    "\n",
    "#body_type\n",
    "# body_type_train = body_type_one[:180000].to_numpy()\n",
    "# body_type_valid = body_type_one[180000:].to_numpy()\n",
    "\n",
    "#age\n",
    "# age_train = train[['age']].to_numpy()\n",
    "# age_valid = valid[['age']].to_numpy()\n",
    "\n",
    "# size\n",
    "# size_train = train[['size']].to_numpy()\n",
    "# size_valid = valid[['size']].to_numpy()\n",
    "\n",
    "# #weight\n",
    "# weight_train = train[['weight']].to_numpy()\n",
    "# weight_valid = valid[['weight']].to_numpy()\n",
    "\n",
    "# #height\n",
    "# height_train = train[['height']].to_numpy()\n",
    "# height_valid = valid[['height']].to_numpy()\n",
    "\n",
    "# #rating\n",
    "rating_train = train[['rating']].to_numpy()\n",
    "rating_valid = valid[['rating']].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', sublinear_tf = True, max_features = 1000, tokenizer = word_tokenize) \n",
    "Train_X_summary = tfidf.fit_transform(train.review_summary).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfVectorizer(stop_words = 'english', sublinear_tf = True, max_features = 1000, tokenizer = word_tokenize) \n",
    "Train_X_text = tfidf2.fit_transform(train.review_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = np.hstack((Train_X_summary, Train_X_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_feature = rating_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsss = []\n",
    "for i in range(180000):\n",
    "    lst = list(combined_text[i]) + list(other_feature[i])\n",
    "    lstsss.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_X_summary = tfidf.transform(valid.review_summary).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Valid_X_text = tfidf2.transform(valid.review_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text_valid = np.hstack((Valid_X_summary, Valid_X_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_feature_valid = rating_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12544, 2000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12544, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_feature_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstsss_valid = []\n",
    "for i in range(12544):\n",
    "    lst = list(combined_text_valid[i]) + list(other_feature_valid[i])\n",
    "    lstsss_valid.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_feature = lstsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kennnnnnn\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(final_feature, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8172831632653061"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(lstsss_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fit', 'large', 'small'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rent['fit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_temp = rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'large'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent_temp['fit'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rent_temp.index:\n",
    "    if rent_temp.loc[i,'fit'] == 'small':\n",
    "        rent_temp.loc[i,'fit'] = 0\n",
    "    if rent_temp.loc[i,'fit'] == 'fit':\n",
    "        rent_temp.loc[i,'fit'] = 1\n",
    "    if rent_temp.loc[i,'fit'] == 'large':\n",
    "        rent_temp.loc[i,'fit'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating\n",
       "rating     1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rent_temp[['fit','rating']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_temp[\"fit\"] = rent_temp[\"fit\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_1 = rent_temp[\"fit\"]\n",
    "column_2 = rent_temp[\"rating\"]\n",
    "correlation = column_1.corr(column_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028358140500538136"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit      9235\n",
       "small    1698\n",
       "large    1611\n",
       "Name: fit, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362085459183674"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9235 / (len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter = 10000, C=0.1)\n",
    "clf.fit(combined_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8038903061224489"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(combined_text_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
